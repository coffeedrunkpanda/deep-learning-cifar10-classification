{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ae483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 11:45:56.759749: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-18 11:45:56.787051: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9360] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-02-18 11:45:56.787072: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-02-18 11:45:56.787096: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1537] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-02-18 11:45:56.792964: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enabled memory growth for 1 GPU(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 11:45:58.502895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-18 11:45:58.519869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-18 11:45:58.521810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-18 11:45:58.523556: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2300] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✅ Enabled memory growth for {len(gpus)} GPU(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5446d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b702e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import load_data\n",
    "\n",
    "dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04fd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.keys()\n",
    "\n",
    "X_train = dataset[\"X_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "\n",
    "X_test= dataset[\"X_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n",
    "labels = dataset[\"labels\"]\n",
    "\n",
    "n_labels = len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b841c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "551a91d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdaf6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029ce318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "y_train_cat = to_categorical(y_train, n_labels)\n",
    "y_test_cat = to_categorical(y_test, n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c11dcdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 12:05:16.529805: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 12.0\n",
      "2026-02-18 12:05:16.529823: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2026-02-18 12:05:16.529855: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.529861: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.529883: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.529899: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.529912: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.529927: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.529943: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.529961: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.754572: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.754727: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.754739: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.754915: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.755337: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.755945: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.756790: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.756801: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-18 12:05:16.757007: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE = len(X_train)  # Total number of examples\n",
    "train_size = int(0.8 * DATASET_SIZE)\n",
    "val_size = int(0.2 * DATASET_SIZE)\n",
    "\n",
    "# 2. Shuffle and split the base dataset (BEFORE batching)\n",
    "# Important: Shuffle first so you don't get all one class in validation\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train_cat))\n",
    "full_dataset = full_dataset.shuffle(buffer_size=1000, seed=42)\n",
    "\n",
    "train_dataset = full_dataset.take(train_size)\n",
    "val_dataset = full_dataset.skip(train_size)\n",
    "\n",
    "\n",
    "def process_batch(image, label, new_size = (96, 96)):\n",
    "    image = tf.image.resize(image, new_size)\n",
    "    image = preprocess_input(image) \n",
    "    return image, label\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 3. Apply your batching/preprocessing pipeline to BOTH\n",
    "def process_pipeline(ds):\n",
    "    return (\n",
    "        ds\n",
    "        .batch(BATCH_SIZE)\n",
    "        .map(process_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "train_ds = process_pipeline(train_dataset)\n",
    "val_ds = process_pipeline(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1ab26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tf.expand_dims(X_train, -1)\n",
    "# #Adds an extra dimension at the end to convert the data shape from (batch_size, 28, 28)\n",
    "# #to (batch_size, 28, 28, 1), which is needed because TensorFlow image functions expect a channel dimension. Here, '1' represents the single grayscale channel.\n",
    "# X_train_resized = tf.image.resize(X_train, (96, 96))\n",
    "# # X_test_resized = tf.image.resize(X_test, (96, 96))\n",
    "\n",
    "# #Converts the grayscale image with shape (96, 96, 1) into a 3-channel RGB image (96, 96, 3)\n",
    "# #by duplicating the single grayscale channel three times. MobileNetV2 expects 3 channels (RGB),\n",
    "# #so this step adapts the Fashion MNIST grayscale images to that format.\n",
    "\n",
    "# # X_train_rgb = tf.image.grayscale_to_rgb(X_train_resized)\n",
    "# # X_test_rgb = tf.image.grayscale_to_rgb(X_test_resized)\n",
    "\n",
    "# # Convert to numpy and preprocess for MobileNetV2\n",
    "# #converts these tensors to NumPy arrays, which some preprocessing functions require.\n",
    "# X_train_rgb = preprocess_input(X_train_resized)\n",
    "# # X_test_rgb = preprocess_input(X_test_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "878de046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
      "9406464/9406464 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Build transfer learning model\n",
    "base_model = MobileNetV2(input_shape=(96, 96, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Freeze base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0501ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(), # Pool spatial features into a vector\n",
    "    layers.Dense(128, activation='relu'), # Fully connected layer to learn new patterns\n",
    "    layers.Dense(n_labels, activation='softmax') # Output layer with 10 classes (Fashion MNIST)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c77f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c432e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 12:05:38.559859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2026-02-18 12:06:18.405756: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/1250 [..............................] - ETA: 20:04:57 - loss: 3.1981 - accuracy: 0.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 12:06:29.850167: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1b0f179b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-02-18 12:06:29.850188: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 5070 Ti, Compute Capability 12.0\n",
      "2026-02-18 12:06:29.852373: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-02-18 12:06:29.869561: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:445] Couldn't read CUDA driver version.\n",
      "2026-02-18 12:06:29.877649: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 66s 6ms/step - loss: 0.5173 - accuracy: 0.8239 - val_loss: 0.4077 - val_accuracy: 0.8563\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3656 - accuracy: 0.8731 - val_loss: 0.4072 - val_accuracy: 0.8577\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3036 - accuracy: 0.8952 - val_loss: 0.4092 - val_accuracy: 0.8595\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2556 - accuracy: 0.9106 - val_loss: 0.4115 - val_accuracy: 0.8589\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2112 - accuracy: 0.9270 - val_loss: 0.4484 - val_accuracy: 0.8554\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "# history = model.fit(X_train_rgb, y_train_cat, validation_split=0.2, epochs=5, batch_size=64)\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# After training/inference\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59c22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
