{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71ba7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from WANDB_API_KEY.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcoffeedrunk\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load variables from env\n",
    "load_dotenv()\n",
    "\n",
    "# Start weights and biases\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd8703c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 09:15:05.677576: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-20 09:15:05.715187: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9360] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-02-20 09:15:05.715218: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-02-20 09:15:05.715243: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1537] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-02-20 09:15:05.729506: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enabled memory growth for 1 GPU(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 09:15:07.234079: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-20 09:15:07.257023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-20 09:15:07.258891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-20 09:15:07.260624: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2300] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Enable memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✅ Enabled memory growth for {len(gpus)} GPU(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Prevent Out Of Memory\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c52f4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 09:15:07.309965: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-20 09:15:07.311936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-20 09:15:07.313632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-20 09:15:07.315395: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2300] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2026-02-20 09:15:07.397652: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-20 09:15:07.398394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-20 09:15:07.399051: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2026-02-20 09:15:07.399127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-20 09:15:07.399801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12321 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5070 Ti, pci bus id: 0000:01:00.0, compute capability: 12.0\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "from utils.data import load_data\n",
    "\n",
    "X_train, y_train, X_test, y_test, labels = load_data()\n",
    "n_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33159a",
   "metadata": {},
   "source": [
    "## Guaxinim Cansado CNN (RaccoonCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import WandbConfig, ExperimentConfig\n",
    "\n",
    "config = ExperimentConfig(input_shape=(32,32,3),\n",
    "                          epochs=20,\n",
    "                          batch_size=32,\n",
    "                          model_name=\"GuaxinimCNN\",\n",
    "                          normalize=False)\n",
    "\n",
    "experiment_name = f\"{config.model_name}_{config.input_shape[0]}_{config.batch_size}\"\n",
    "\n",
    "wandb_config = WandbConfig(project_name=\"deep-learning-cifar10-classification_custom\",\n",
    "                           experiment_name=experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eb4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train import run_experiment\n",
    "\n",
    "(train_ds,\n",
    " val_ds,\n",
    " test_ds,\n",
    " model,\n",
    " history,\n",
    " run) = run_experiment(X_train, y_train,\n",
    "               X_test, y_test,\n",
    "               wandb_config=wandb_config,\n",
    "               config=config,\n",
    "               class_names = labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a0bdc",
   "metadata": {},
   "source": [
    "## Testing parameters and models: Custom CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import WandbConfig, ExperimentConfig\n",
    "\n",
    "input_arr = [32, 64, 224]\n",
    "batch_arr = [32,64,128]\n",
    "model_arr = [\"GuaxinimCNN\", \"baseline_cnn\", \"deeper_cnn\"]\n",
    "\n",
    "for size in input_arr:\n",
    "    for batch in batch_arr:\n",
    "        for model_name in model_arr:\n",
    "\n",
    "            try: \n",
    "                config = ExperimentConfig(input_shape=(size,size,3),\n",
    "                                        epochs=30,\n",
    "                                        batch_size=batch,\n",
    "                                        model_name=model_name,\n",
    "                                        normalize=True)\n",
    "\n",
    "                experiment_name = f\"{config.model_name}_{config.input_shape[0]}_{config.batch_size}_norm\"\n",
    "\n",
    "                wandb_config = WandbConfig(project_name=\"deep-learning-cifar10-classification_custom\",\n",
    "                                        experiment_name=experiment_name)\n",
    "\n",
    "\n",
    "                from utils.train import run_experiment\n",
    "\n",
    "                (train_ds,\n",
    "                val_ds,\n",
    "                test_ds,\n",
    "                model,\n",
    "                history,\n",
    "                run) = run_experiment(X_train, y_train,\n",
    "                            X_test, y_test,\n",
    "                            wandb_config=wandb_config,\n",
    "                            config=config,\n",
    "                            class_names = labels)\n",
    "\n",
    "            except:\n",
    "                print(f\"Could not run with the parameters: {size}, {batch}, {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b3ae7",
   "metadata": {},
   "source": [
    "## Testing parameters and models: Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81f23fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pydantic/main.py:308: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
      "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.25.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/var/home/anne/Documents/_Ironhack/deep-learning-cifar10-classification/wandb/run-20260220_091513-0m2maeob</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final/runs/0m2maeob' target=\"_blank\">MobileNetV2_224_128</a></strong> to <a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final' target=\"_blank\">https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final/runs/0m2maeob' target=\"_blank\">https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final/runs/0m2maeob</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 09:15:14.455475: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 12.0\n",
      "2026-02-20 09:15:14.455489: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2026-02-20 09:15:14.455543: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.456949: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.456970: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.456987: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.457004: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.457017: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.457034: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.468966: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.651539: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.651562: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.651854: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.652008: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.652018: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.652237: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.652502: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.652895: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:15:14.653372: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 09:15:20.249383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2026-02-20 09:16:00.357359: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/313 [..............................] - ETA: 4:44:18 - loss: 2.5010 - accuracy: 0.1094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 09:16:10.616278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6a4c1f5ac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-02-20 09:16:10.616299: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 5070 Ti, Compute Capability 12.0\n",
      "2026-02-20 09:16:10.618481: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-02-20 09:16:10.636934: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:445] Couldn't read CUDA driver version.\n",
      "2026-02-20 09:16:10.645215: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 75s 65ms/step - loss: 0.5764 - accuracy: 0.8020 - val_loss: 0.4716 - val_accuracy: 0.8343\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.4279 - accuracy: 0.8512 - val_loss: 0.4396 - val_accuracy: 0.8459\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3751 - accuracy: 0.8686 - val_loss: 0.4213 - val_accuracy: 0.8562\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3435 - accuracy: 0.8809 - val_loss: 0.4101 - val_accuracy: 0.8573\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.3138 - accuracy: 0.8907 - val_loss: 0.4173 - val_accuracy: 0.8568\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.2846 - accuracy: 0.9011 - val_loss: 0.4064 - val_accuracy: 0.8648\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.2609 - accuracy: 0.9093 - val_loss: 0.4048 - val_accuracy: 0.8641\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.2398 - accuracy: 0.9190 - val_loss: 0.4892 - val_accuracy: 0.8472\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.2203 - accuracy: 0.9231 - val_loss: 0.4181 - val_accuracy: 0.8701\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.1969 - accuracy: 0.9330 - val_loss: 0.4227 - val_accuracy: 0.8661\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.1755 - accuracy: 0.9408 - val_loss: 0.4473 - val_accuracy: 0.8622\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 0.1611 - accuracy: 0.9459 - val_loss: 0.4785 - val_accuracy: 0.8592\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.4571 - accuracy: 0.8480\n",
      "4/4 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Data passed to `wandb.Image` should consist of values in the range [0, 255], image data will be normalized to this range, but behavior will be removed in a future version of wandb.\n",
      "WARNING:root:Only 108 Image will be uploaded.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▃▄▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▅▄▄▃▃▂▂▂▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▅▅▅▇▇▄█▇▆▆</td></tr><tr><td>epoch/val_loss</td><td>▇▄▂▁▂▁▁█▂▂▅▇</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.9459</td></tr><tr><td>epoch/epoch</td><td>11</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.16108</td></tr><tr><td>epoch/val_accuracy</td><td>0.8592</td></tr><tr><td>epoch/val_loss</td><td>0.47846</td></tr><tr><td>final_val_accuracy</td><td>0.848</td></tr><tr><td>final_val_loss</td><td>0.45709</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MobileNetV2_224_128</strong> at: <a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final/runs/0m2maeob' target=\"_blank\">https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final/runs/0m2maeob</a><br> View project at: <a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final' target=\"_blank\">https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final</a><br>Synced 5 W&B file(s), 108 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260220_091513-0m2maeob/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pydantic/main.py:308: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
      "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.25.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/var/home/anne/Documents/_Ironhack/deep-learning-cifar10-classification/wandb/run-20260220_092003-671wm169</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final/runs/671wm169' target=\"_blank\">ConvNeXtTiny_224_128</a></strong> to <a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final' target=\"_blank\">https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final/runs/671wm169' target=\"_blank\">https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final/runs/671wm169</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 09:20:08.002059: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.076024: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.076049: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.076063: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.076424: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.076642: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.077879: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.077892: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.077903: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.229768: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.230693: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.230719: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.230928: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.230937: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.231510: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.231903: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.231910: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:08.338969: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2026-02-20 09:20:13.952876: W tensorflow/compiler/xla/service/gpu/buffer_comparator.cc:1052] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Setting XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda  or modifying $PATH can be used to set the location of ptxas\n",
      "This message will only be logged once.\n",
      "2026-02-20 09:20:26.432682: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 140s 374ms/step - loss: 0.3924 - accuracy: 0.8776 - val_loss: 0.2547 - val_accuracy: 0.9155\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 110s 353ms/step - loss: 0.2267 - accuracy: 0.9243 - val_loss: 0.2251 - val_accuracy: 0.9261\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.1963 - accuracy: 0.9336 - val_loss: 0.2156 - val_accuracy: 0.9286\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.1750 - accuracy: 0.9414 - val_loss: 0.2159 - val_accuracy: 0.9266\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.1580 - accuracy: 0.9467 - val_loss: 0.2090 - val_accuracy: 0.9304\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.1416 - accuracy: 0.9530 - val_loss: 0.2132 - val_accuracy: 0.9305\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.1277 - accuracy: 0.9576 - val_loss: 0.2062 - val_accuracy: 0.9326\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.1134 - accuracy: 0.9633 - val_loss: 0.2193 - val_accuracy: 0.9295\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.1012 - accuracy: 0.9669 - val_loss: 0.2144 - val_accuracy: 0.9309\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.0888 - accuracy: 0.9719 - val_loss: 0.2222 - val_accuracy: 0.9306\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.0761 - accuracy: 0.9774 - val_loss: 0.2213 - val_accuracy: 0.9316\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 110s 352ms/step - loss: 0.0659 - accuracy: 0.9811 - val_loss: 0.2309 - val_accuracy: 0.9299\n",
      "79/79 [==============================] - 22s 276ms/step - loss: 0.2359 - accuracy: 0.9221\n",
      "4/4 [==============================] - 3s 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Only 108 Image will be uploaded.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▄▅▅▆▆▆▇▇▇██</td></tr><tr><td>epoch/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▄▃▃▃▂▂▂▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▅▆▆▇▇█▇▇▇█▇</td></tr><tr><td>epoch/val_loss</td><td>█▄▂▂▁▂▁▃▂▃▃▅</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.9811</td></tr><tr><td>epoch/epoch</td><td>11</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.06591</td></tr><tr><td>epoch/val_accuracy</td><td>0.9299</td></tr><tr><td>epoch/val_loss</td><td>0.23092</td></tr><tr><td>final_val_accuracy</td><td>0.9221</td></tr><tr><td>final_val_loss</td><td>0.2359</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ConvNeXtTiny_224_128</strong> at: <a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final/runs/671wm169' target=\"_blank\">https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final/runs/671wm169</a><br> View project at: <a href='https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final' target=\"_blank\">https://wandb.ai/coffeedrunk/deep-learning-cifar10-classification_final</a><br>Synced 5 W&B file(s), 108 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260220_092003-671wm169/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.config import WandbConfig, ExperimentConfig\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# input_arr = [64, 96, 224]\n",
    "input_arr = [224]\n",
    "# batch_arr = [64,128]\n",
    "batch_arr = [128]\n",
    "lr_arr = [1e-3]\n",
    "model_arr = [\"MobileNetV2\", \"ConvNeXtTiny\"]\n",
    "\n",
    "for size in input_arr:\n",
    "    for batch in batch_arr:\n",
    "        for model_name in model_arr:\n",
    "            for lr in lr_arr:\n",
    "\n",
    "                try: \n",
    "                    config = ExperimentConfig(input_shape=(size,size,3),\n",
    "                                            epochs=20,\n",
    "                                            batch_size=batch,\n",
    "                                            model_name=model_name,\n",
    "                                            normalize=False,\n",
    "                                            learning_rate=lr,\n",
    "                                            augment=False)\n",
    "\n",
    "                    experiment_name = f\"{config.model_name}_{config.input_shape[0]}_{config.batch_size}\"\n",
    "\n",
    "                    wandb_config = WandbConfig(project_name=\"deep-learning-cifar10-classification_final\",\n",
    "                                            experiment_name=experiment_name)\n",
    "\n",
    "\n",
    "                    from utils.train import run_experiment\n",
    "\n",
    "                    if model_name == \"MobileNetV2\":\n",
    "                        preprocess_fn = preprocess_input\n",
    "\n",
    "                    else:\n",
    "                        preprocess_fn = None\n",
    "\n",
    "                    (train_ds,\n",
    "                    val_ds,\n",
    "                    test_ds,\n",
    "                    model,\n",
    "                    history,\n",
    "                    run) = run_experiment(X_train, y_train,\n",
    "                                X_test, y_test,\n",
    "                                wandb_config=wandb_config,\n",
    "                                config=config,\n",
    "                                class_names = labels,\n",
    "                                preprocess_fn=preprocess_fn)\n",
    "\n",
    "                except:\n",
    "                    print(f\"Could not run with the parameters: {size}, {batch}, {model_name}, {lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd5bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
